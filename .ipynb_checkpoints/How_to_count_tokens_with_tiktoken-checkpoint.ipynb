{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76f3a2cb-31fd-49e7-8ea9-7e1fac181b29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32900381-7759-440e-b951-399f9c413dc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoding = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2134947d-ba59-486c-a94d-0c15a161c3b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[83, 1134, 30001, 318, 1049, 0]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding.encode(\"tiktoken is great!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b12279f5-5033-4380-be21-e795d9336a2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8cff191-ed1d-47a2-a141-9c52fd70b3d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens_from_string(\"tiktoken is great!\", \"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a3430d3-84c7-425e-b56a-aa2833d25633",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tiktoken is great!'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding.decode([83, 1134, 30001, 318, 1049, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c21a2fc2-2d19-4ce3-9ee7-e3c7f7039e07",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b't', b'ik', b'token', b' is', b' great', b'!']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[encoding.decode_single_token_bytes(token) for token in [83, 1134, 30001, 318, 1049, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f607f9ee-f37b-4a81-8829-3351f25dc102",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compare_encodings(example_string: str) -> None:\n",
    "    \"\"\"Prints a comparison of three string encodings.\"\"\"\n",
    "    # print the example string\n",
    "    print(f'\\nExample string: \"{example_string}\"')\n",
    "    # for each encoding, print the # of tokens, the token integers, and the token bytes\n",
    "    for encoding_name in [\"gpt2\", \"p50k_base\", \"cl100k_base\"]:\n",
    "        encoding = tiktoken.get_encoding(encoding_name)\n",
    "        token_integers = encoding.encode(example_string)\n",
    "        num_tokens = len(token_integers)\n",
    "        token_bytes = [encoding.decode_single_token_bytes(token) for token in token_integers]\n",
    "        print()\n",
    "        print(f\"{encoding_name}: {num_tokens} tokens\")\n",
    "        print(f\"token integers: {token_integers}\")\n",
    "        print(f\"token bytes: {token_bytes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1077cff5-d712-4ff7-9960-ad90f6450a4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example string: \"antidisestablishmentarianism\"\n",
      "\n",
      "gpt2: 5 tokens\n",
      "token integers: [415, 29207, 44390, 3699, 1042]\n",
      "token bytes: [b'ant', b'idis', b'establishment', b'arian', b'ism']\n",
      "\n",
      "p50k_base: 5 tokens\n",
      "token integers: [415, 29207, 44390, 3699, 1042]\n",
      "token bytes: [b'ant', b'idis', b'establishment', b'arian', b'ism']\n",
      "\n",
      "cl100k_base: 6 tokens\n",
      "token integers: [519, 85342, 34500, 479, 8997, 2191]\n",
      "token bytes: [b'ant', b'idis', b'establish', b'ment', b'arian', b'ism']\n"
     ]
    }
   ],
   "source": [
    "compare_encodings(\"antidisestablishmentarianism\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8e6f6ff-0981-4710-ba40-094934b0da6a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example string: \"2 + 2 = 4\"\n",
      "\n",
      "gpt2: 5 tokens\n",
      "token integers: [17, 1343, 362, 796, 604]\n",
      "token bytes: [b'2', b' +', b' 2', b' =', b' 4']\n",
      "\n",
      "p50k_base: 5 tokens\n",
      "token integers: [17, 1343, 362, 796, 604]\n",
      "token bytes: [b'2', b' +', b' 2', b' =', b' 4']\n",
      "\n",
      "cl100k_base: 7 tokens\n",
      "token integers: [17, 489, 220, 17, 284, 220, 19]\n",
      "token bytes: [b'2', b' +', b' ', b'2', b' =', b' ', b'4']\n"
     ]
    }
   ],
   "source": [
    "compare_encodings(\"2 + 2 = 4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a331e69-dccc-4caa-9599-fe307707b297",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example string: \"お誕生日おめでとう\"\n",
      "\n",
      "gpt2: 14 tokens\n",
      "token integers: [2515, 232, 45739, 243, 37955, 33768, 98, 2515, 232, 1792, 223, 30640, 30201, 29557]\n",
      "token bytes: [b'\\xe3\\x81', b'\\x8a', b'\\xe8\\xaa', b'\\x95', b'\\xe7\\x94\\x9f', b'\\xe6\\x97', b'\\xa5', b'\\xe3\\x81', b'\\x8a', b'\\xe3\\x82', b'\\x81', b'\\xe3\\x81\\xa7', b'\\xe3\\x81\\xa8', b'\\xe3\\x81\\x86']\n",
      "\n",
      "p50k_base: 14 tokens\n",
      "token integers: [2515, 232, 45739, 243, 37955, 33768, 98, 2515, 232, 1792, 223, 30640, 30201, 29557]\n",
      "token bytes: [b'\\xe3\\x81', b'\\x8a', b'\\xe8\\xaa', b'\\x95', b'\\xe7\\x94\\x9f', b'\\xe6\\x97', b'\\xa5', b'\\xe3\\x81', b'\\x8a', b'\\xe3\\x82', b'\\x81', b'\\xe3\\x81\\xa7', b'\\xe3\\x81\\xa8', b'\\xe3\\x81\\x86']\n",
      "\n",
      "cl100k_base: 9 tokens\n",
      "token integers: [33334, 45918, 243, 21990, 9080, 33334, 62004, 16556, 78699]\n",
      "token bytes: [b'\\xe3\\x81\\x8a', b'\\xe8\\xaa', b'\\x95', b'\\xe7\\x94\\x9f', b'\\xe6\\x97\\xa5', b'\\xe3\\x81\\x8a', b'\\xe3\\x82\\x81', b'\\xe3\\x81\\xa7', b'\\xe3\\x81\\xa8\\xe3\\x81\\x86']\n"
     ]
    }
   ],
   "source": [
    "compare_encodings(\"お誕生日おめでとう\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa9c8bf4-ae0d-461b-ac7b-ab1bda40ca3d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example string: \"모두가 인공지능에 대해 환호 할 때 그 한계를 한번 생각해 보자.\"\n",
      "\n",
      "gpt2: 76 tokens\n",
      "token integers: [167, 103, 101, 167, 239, 238, 166, 108, 222, 23821, 251, 116, 166, 111, 113, 168, 100, 222, 167, 232, 98, 168, 245, 238, 31619, 234, 222, 47991, 112, 220, 169, 247, 246, 169, 246, 116, 220, 47991, 254, 31619, 243, 234, 220, 166, 115, 116, 220, 47991, 250, 166, 111, 226, 167, 98, 120, 220, 47991, 250, 167, 110, 230, 23821, 225, 251, 166, 108, 223, 47991, 112, 31619, 111, 112, 168, 252, 238, 13]\n",
      "token bytes: [b'\\xeb', b'\\xaa', b'\\xa8', b'\\xeb', b'\\x91', b'\\x90', b'\\xea', b'\\xb0', b'\\x80', b' \\xec', b'\\x9d', b'\\xb8', b'\\xea', b'\\xb3', b'\\xb5', b'\\xec', b'\\xa7', b'\\x80', b'\\xeb', b'\\x8a', b'\\xa5', b'\\xec', b'\\x97', b'\\x90', b' \\xeb', b'\\x8c', b'\\x80', b'\\xed\\x95', b'\\xb4', b' ', b'\\xed', b'\\x99', b'\\x98', b'\\xed', b'\\x98', b'\\xb8', b' ', b'\\xed\\x95', b'\\xa0', b' \\xeb', b'\\x95', b'\\x8c', b' ', b'\\xea', b'\\xb7', b'\\xb8', b' ', b'\\xed\\x95', b'\\x9c', b'\\xea', b'\\xb3', b'\\x84', b'\\xeb', b'\\xa5', b'\\xbc', b' ', b'\\xed\\x95', b'\\x9c', b'\\xeb', b'\\xb2', b'\\x88', b' \\xec', b'\\x83', b'\\x9d', b'\\xea', b'\\xb0', b'\\x81', b'\\xed\\x95', b'\\xb4', b' \\xeb', b'\\xb3', b'\\xb4', b'\\xec', b'\\x9e', b'\\x90', b'.']\n",
      "\n",
      "p50k_base: 76 tokens\n",
      "token integers: [167, 103, 101, 167, 239, 238, 166, 108, 222, 23821, 251, 116, 166, 111, 113, 168, 100, 222, 167, 232, 98, 168, 245, 238, 31619, 234, 222, 47991, 112, 220, 169, 247, 246, 169, 246, 116, 220, 47991, 254, 31619, 243, 234, 220, 166, 115, 116, 220, 47991, 250, 166, 111, 226, 167, 98, 120, 220, 47991, 250, 167, 110, 230, 23821, 225, 251, 166, 108, 223, 47991, 112, 31619, 111, 112, 168, 252, 238, 13]\n",
      "token bytes: [b'\\xeb', b'\\xaa', b'\\xa8', b'\\xeb', b'\\x91', b'\\x90', b'\\xea', b'\\xb0', b'\\x80', b' \\xec', b'\\x9d', b'\\xb8', b'\\xea', b'\\xb3', b'\\xb5', b'\\xec', b'\\xa7', b'\\x80', b'\\xeb', b'\\x8a', b'\\xa5', b'\\xec', b'\\x97', b'\\x90', b' \\xeb', b'\\x8c', b'\\x80', b'\\xed\\x95', b'\\xb4', b' ', b'\\xed', b'\\x99', b'\\x98', b'\\xed', b'\\x98', b'\\xb8', b' ', b'\\xed\\x95', b'\\xa0', b' \\xeb', b'\\x95', b'\\x8c', b' ', b'\\xea', b'\\xb7', b'\\xb8', b' ', b'\\xed\\x95', b'\\x9c', b'\\xea', b'\\xb3', b'\\x84', b'\\xeb', b'\\xa5', b'\\xbc', b' ', b'\\xed\\x95', b'\\x9c', b'\\xeb', b'\\xb2', b'\\x88', b' \\xec', b'\\x83', b'\\x9d', b'\\xea', b'\\xb0', b'\\x81', b'\\xed\\x95', b'\\xb4', b' \\xeb', b'\\xb3', b'\\xb4', b'\\xec', b'\\x9e', b'\\x90', b'.']\n",
      "\n",
      "cl100k_base: 31 tokens\n",
      "token integers: [41847, 101, 167, 80010, 20565, 59777, 79225, 22035, 67119, 19954, 62060, 34983, 47932, 246, 48424, 96102, 54718, 55925, 62398, 22783, 226, 18918, 62398, 43144, 48918, 14705, 223, 34983, 64432, 26799, 13]\n",
      "token bytes: [b'\\xeb\\xaa', b'\\xa8', b'\\xeb', b'\\x91\\x90', b'\\xea\\xb0\\x80', b' \\xec\\x9d\\xb8', b'\\xea\\xb3\\xb5', b'\\xec\\xa7\\x80', b'\\xeb\\x8a\\xa5', b'\\xec\\x97\\x90', b' \\xeb\\x8c\\x80', b'\\xed\\x95\\xb4', b' \\xed\\x99', b'\\x98', b'\\xed\\x98\\xb8', b' \\xed\\x95\\xa0', b' \\xeb\\x95\\x8c', b' \\xea\\xb7\\xb8', b' \\xed\\x95\\x9c', b'\\xea\\xb3', b'\\x84', b'\\xeb\\xa5\\xbc', b' \\xed\\x95\\x9c', b'\\xeb\\xb2\\x88', b' \\xec\\x83\\x9d', b'\\xea\\xb0', b'\\x81', b'\\xed\\x95\\xb4', b' \\xeb\\xb3\\xb4', b'\\xec\\x9e\\x90', b'.']\n"
     ]
    }
   ],
   "source": [
    "compare_encodings(\"모두가 인공지능에 대해 환호 할 때 그 한계를 한번 생각해 보자.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05cf1701-9a65-4f70-8be6-24fb4363a585",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example string: \"Olympia is the capital of the U.S. state of Washington and the county seat and largest city of Thurston County.\"\n",
      "\n",
      "gpt2: 27 tokens\n",
      "token integers: [46, 6760, 544, 318, 262, 3139, 286, 262, 471, 13, 50, 13, 1181, 286, 2669, 290, 262, 7968, 5852, 290, 4387, 1748, 286, 36975, 3743, 3418, 13]\n",
      "token bytes: [b'O', b'lymp', b'ia', b' is', b' the', b' capital', b' of', b' the', b' U', b'.', b'S', b'.', b' state', b' of', b' Washington', b' and', b' the', b' county', b' seat', b' and', b' largest', b' city', b' of', b' Thur', b'ston', b' County', b'.']\n",
      "\n",
      "p50k_base: 27 tokens\n",
      "token integers: [46, 6760, 544, 318, 262, 3139, 286, 262, 471, 13, 50, 13, 1181, 286, 2669, 290, 262, 7968, 5852, 290, 4387, 1748, 286, 36975, 3743, 3418, 13]\n",
      "token bytes: [b'O', b'lymp', b'ia', b' is', b' the', b' capital', b' of', b' the', b' U', b'.', b'S', b'.', b' state', b' of', b' Washington', b' and', b' the', b' county', b' seat', b' and', b' largest', b' city', b' of', b' Thur', b'ston', b' County', b'.']\n",
      "\n",
      "cl100k_base: 26 tokens\n",
      "token integers: [46, 14163, 689, 374, 279, 6864, 315, 279, 549, 815, 13, 1614, 315, 6652, 323, 279, 14189, 10954, 323, 7928, 3363, 315, 76155, 7876, 6406, 13]\n",
      "token bytes: [b'O', b'lymp', b'ia', b' is', b' the', b' capital', b' of', b' the', b' U', b'.S', b'.', b' state', b' of', b' Washington', b' and', b' the', b' county', b' seat', b' and', b' largest', b' city', b' of', b' Thur', b'ston', b' County', b'.']\n"
     ]
    }
   ],
   "source": [
    "compare_encodings(\"Olympia is the capital of the U.S. state of Washington and the county seat and largest city of Thurston County.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fac4bb-c212-4611-8e2e-ad8aa0f2b6b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
